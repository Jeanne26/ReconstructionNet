{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd2c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "from torch.utils.data import Dataset, Subset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "367a4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()   #[0,255] â†’ [0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "082d35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, images_dir, groundtruth_csv, transform=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.df = pd.read_csv(groundtruth_csv)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_ids = self.df[\"image\"].values\n",
    "        self.labels = self.df[CLASSES].values.argmax(axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "        img_path = self.images_dir / f\"{image_id}.jpg\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7921ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded\n",
      "Train: 10015\n",
      "Val  : 193\n",
      "Test : 1512\n"
     ]
    }
   ],
   "source": [
    "path_data = Path(\"../data/isic\")\n",
    "\n",
    "train_dataset = ISICDataset(\n",
    "    images_dir=path_data / \"train\",  \n",
    "    groundtruth_csv=path_data / \"train\" / \"groundtruth.csv\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = ISICDataset(\n",
    "    images_dir=path_data / \"val\",\n",
    "    groundtruth_csv=path_data / \"val\" / \"groundtruth.csv\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = ISICDataset(\n",
    "    images_dir=path_data / \"test\", \n",
    "    groundtruth_csv=path_data / \"test\" / \"groundtruth.csv\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(\"Datasets loaded\")\n",
    "print(\"Train:\", len(train_dataset))\n",
    "print(\"Val  :\", len(val_dataset))\n",
    "print(\"Test :\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2413e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9490, 0.9569, 0.9569,  ..., 0.9569, 0.9529, 0.9490],\n",
       "          [0.9451, 0.9490, 0.9529,  ..., 0.9451, 0.9412, 0.9451],\n",
       "          [0.9255, 0.9294, 0.9373,  ..., 0.9490, 0.9451, 0.9412],\n",
       "          ...,\n",
       "          [0.8863, 0.8902, 0.8784,  ..., 0.8667, 0.8549, 0.8549],\n",
       "          [0.8863, 0.8824, 0.8863,  ..., 0.8667, 0.8667, 0.8588],\n",
       "          [0.8863, 0.8784, 0.8824,  ..., 0.8706, 0.8706, 0.8549]],\n",
       " \n",
       "         [[0.5804, 0.5922, 0.5922,  ..., 0.5922, 0.5922, 0.5843],\n",
       "          [0.5608, 0.5725, 0.5843,  ..., 0.5804, 0.5804, 0.5843],\n",
       "          [0.5373, 0.5451, 0.5608,  ..., 0.5843, 0.5843, 0.5882],\n",
       "          ...,\n",
       "          [0.5451, 0.5490, 0.5333,  ..., 0.5569, 0.5569, 0.5490],\n",
       "          [0.5608, 0.5608, 0.5608,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5608, 0.5608, 0.5608,  ..., 0.5569, 0.5647, 0.5608]],\n",
       " \n",
       "         [[0.6549, 0.6627, 0.6706,  ..., 0.6745, 0.6745, 0.6627],\n",
       "          [0.6431, 0.6549, 0.6588,  ..., 0.6627, 0.6588, 0.6627],\n",
       "          [0.6235, 0.6314, 0.6392,  ..., 0.6667, 0.6627, 0.6627],\n",
       "          ...,\n",
       "          [0.5686, 0.5725, 0.5608,  ..., 0.5725, 0.5608, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5686,  ..., 0.5765, 0.5804, 0.5686],\n",
       "          [0.5490, 0.5490, 0.5608,  ..., 0.5686, 0.5765, 0.5725]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a256ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Counter({1: 6705, 0: 1113, 4: 1099, 2: 514, 3: 327, 6: 142, 5: 115})\n",
      "Val distribution  : Counter({1: 123, 4: 22, 0: 21, 2: 15, 3: 8, 6: 3, 5: 1})\n",
      "Test distribution : Counter({1: 909, 4: 217, 0: 171, 2: 93, 5: 44, 3: 43, 6: 35})\n"
     ]
    }
   ],
   "source": [
    "print(\"Train distribution:\", Counter(train_dataset.labels))\n",
    "print(\"Val distribution  :\", Counter(val_dataset.labels))\n",
    "print(\"Test distribution :\", Counter(test_dataset.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7128fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_by_class(dataset):\n",
    "    class_subsets = {}\n",
    "    for c in range(len(CLASSES)):\n",
    "        indices = [i for i, y in enumerate(dataset.labels) if y == c]\n",
    "        class_subsets[c] = Subset(dataset, indices)\n",
    "    return class_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442aa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class MEL: 1113 images\n",
      "Class NV: 6705 images\n",
      "Class BCC: 514 images\n",
      "Class AKIEC: 327 images\n",
      "Class BKL: 1099 images\n",
      "Class DF: 115 images\n",
      "Class VASC: 142 images\n"
     ]
    }
   ],
   "source": [
    "train_sets_by_class = split_dataset_by_class(train_dataset)\n",
    "for c in train_sets_by_class:\n",
    "    print(f\"Class {CLASSES[c]}: {len(train_sets_by_class[c])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de844dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = Path(\"../data/processed_data/isic\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "torch.save(train_dataset, SAVE_DIR / \"train_dataset.pt\")\n",
    "torch.save(val_dataset, SAVE_DIR / \"val_dataset.pt\")\n",
    "torch.save(test_dataset, SAVE_DIR / \"test_dataset.pt\")\n",
    "\n",
    "torch.save(train_sets_by_class, SAVE_DIR / \"train_sets_by_class.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This how to get the data from the files\n",
    "\n",
    "train_dataset = torch.load(\"../data/processed_data/isic/train_dataset.pt\")\n",
    "val_dataset = torch.load(\"../data/processed_data/isic/val_dataset.pt\")\n",
    "test_dataset = torch.load(\"../data/processed_data/isic/test_dataset.pt\")\n",
    "train_sets_by_class = torch.load(\"../data/processed_data/isic/train_sets_by_class.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
